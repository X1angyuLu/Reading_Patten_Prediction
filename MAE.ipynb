{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from dataloader import dataset\n",
    "from model import FFD, TRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(truth, ReP):\n",
    "    ReP = ReP[0].to(device)\n",
    "    truth = truth.to(device)\n",
    "    loss = torch.mean(torch.abs(truth-ReP))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(FFD, TRT, valloader):\n",
    "    lf = 0\n",
    "    lt = 0\n",
    "    loop = tqdm(enumerate(valloader, start=len(valloader)), total=len(valloader), leave=False)\n",
    "    for step, (sentence,FFDAvg, FFDStd,TRTAvg,TRTStd) in loop:\n",
    "        sentence = [w[0] for w in sentence]\n",
    "        # True_FFD = torch.cat((FFDAvg,FFDStd)).T\n",
    "        True_TRT = torch.cat((TRTAvg,TRTStd)).T\n",
    "\n",
    "        # FFD_I = FFD(sentence)\n",
    "        TRT_I = TRT(sentence)\n",
    "\n",
    "        # lossF = loss_fn(True_FFD, FFD_I)\n",
    "        lossT = loss_fn(True_TRT, TRT_I)\n",
    "\n",
    "        # lf = lf+lossF\n",
    "        lt = lt+lossT\n",
    "    \n",
    "    lf = lf/len(valloader)\n",
    "    lt = lt/len(valloader)\n",
    "\n",
    "    return lf, lt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(FFD, TRT, trainloader, valloader, epochs, optimizerF, optimizerT):\n",
    "    writer = SummaryWriter(\"./log/\")\n",
    "    best_lf = 1000\n",
    "    best_lt = 1000\n",
    "    for epoch in range(epochs):\n",
    "        loop = tqdm(enumerate(trainloader, start=epoch * len(trainloader)), total=len(trainloader), leave=False)\n",
    "        lf = 0\n",
    "        lt = 0\n",
    " \n",
    "        for step, (sentence,FFDAvg, FFDStd,TRTAvg,TRTStd) in loop:\n",
    "            sentence = [w[0] for w in sentence]\n",
    "            # True_FFD = torch.cat((FFDAvg,FFDStd)).T\n",
    "            True_TRT = torch.cat((TRTAvg,TRTStd)).T\n",
    "\n",
    "            # optimizerF.param_groups[0]['lr'] = 0.000001#adjust_learning_rate(epochs, batch_size, trainloader, step)\n",
    "            # optimizerF.zero_grad()\n",
    "\n",
    "            optimizerT.param_groups[0]['lr'] = 0.000001#adjust_learning_rate(epochs, batch_size, trainloader, step)\n",
    "            optimizerT.zero_grad()\n",
    "\n",
    "            # FFD_I = FFD(sentence)\n",
    "            TRT_I = TRT(sentence)\n",
    "\n",
    "            # lossF = loss_fn(True_FFD, FFD_I)\n",
    "            # lossF.backward()\n",
    "            # optimizerF.step()\n",
    "\n",
    "            lossT = loss_fn(True_TRT, TRT_I)\n",
    "            lossT.backward()\n",
    "            optimizerT.step()\n",
    "\n",
    "            # lf = lf+lossF\n",
    "            lt = lt+lossT\n",
    "\n",
    "            # writer.add_scalar(\"LossF/LossT/train\", lossF, lossT, epoch)\n",
    "\n",
    "            loop.set_description(f'Epoch [{epoch}/{epochs}]')\n",
    "            # loop.set_postfix(loss = lossF.cpu().detach().numpy())\n",
    "            loop.set_postfix(loss = lossT.cpu().detach().numpy())\n",
    "\n",
    "        lf = lf/len(trainloader)\n",
    "        lt = lt/len(trainloader)\n",
    "        # print(f'Loss for epoch {epoch} is {lf.cpu().detach().numpy()} and {lt.cpu().detach().numpy()}')\n",
    "        lf, lt = eval(FFD, TRT, valloader)\n",
    "        # print(f'Loss for epoch {epoch} is {lf.cpu().detach().numpy()} and {lt.cpu().detach().numpy()}')\n",
    "\n",
    "        # if best_lf>lf:\n",
    "        #     best_lf = lf\n",
    "        #     torch.save(FFD.state_dict(), os.path.join('.', 'checkpoints',  'best_checkpointF'+str(lf.item())+'.pth'))\n",
    "        if best_lt>lt:\n",
    "            best_lt = lt\n",
    "            torch.save(TRT.state_dict(), os.path.join('.', 'checkpoints',  'best_checkpointT'+str(lt.item())+'.pth'))\n",
    "        \n",
    "    print('End of the Training. Saving final checkpoints.')\n",
    "\n",
    "    state = dict(epoch=epochs, model=FFD.state_dict(),\n",
    "                 optimizer=optimizerF.state_dict())\n",
    "    torch.save(state, os.path.join('.', 'checkpoints',  'final_checkpointF.pth'))\n",
    "\n",
    "    state = dict(epoch=epochs, model=TRT.state_dict(),\n",
    "                 optimizer=optimizerT.state_dict())\n",
    "    torch.save(state, os.path.join('.', 'checkpoints',  'final_checkpointT.pth'))\n",
    "\n",
    "    writer.flush()\n",
    "    writer.close()    \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_set = dataset(file_path='c:\\\\Users\\\\ludandan\\\\Desktop\\\\CCS3\\\\dataset\\\\Training\\\\train.csv', language='en')\n",
    "trainingloader = DataLoader(dataset=Training_set,batch_size=1,shuffle=True)\n",
    "\n",
    "Val_set = dataset(file_path='c:\\\\Users\\\\ludandan\\\\Desktop\\\\CCS3\\\\dataset\\\\EvaluationSubtask1.txt', language='en')\n",
    "valloader = DataLoader(dataset=Val_set,batch_size=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "ffd = FFD(padding=False).to(device)\n",
    "optimizerF = torch.optim.Adam(filter(lambda p: p.requires_grad, ffd.parameters()),\n",
    "                lr=0.1,\n",
    "                betas=(0.9, 0.999),\n",
    "                eps=1e-08,\n",
    "                weight_decay=0,\n",
    "                amsgrad=False)\n",
    "\n",
    "\n",
    "trt = TRT(padding=False).to(device)\n",
    "optimizerT = torch.optim.Adam(filter(lambda p: p.requires_grad, trt.parameters()),\n",
    "                lr=0.1,\n",
    "                betas=(0.9, 0.999),\n",
    "                eps=1e-08,\n",
    "                weight_decay=0,\n",
    "                amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                       \r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument tensors in method wrapper_cat)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m\n\u001b[0;32m      3\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mffd\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrt\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrainingloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizerF\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizerT\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[16], line 22\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(FFD, TRT, trainloader, valloader, epochs, optimizerF, optimizerT)\u001b[0m\n\u001b[0;32m     19\u001b[0m optimizerT\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# FFD_I = FFD(sentence)\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m TRT_I \u001b[38;5;241m=\u001b[39m \u001b[43mTRT\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# lossF = loss_fn(True_FFD, FFD_I)\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# lossF.backward()\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# optimizerF.step()\u001b[39;00m\n\u001b[0;32m     28\u001b[0m lossT \u001b[38;5;241m=\u001b[39m loss_fn(True_TRT, TRT_I)\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\ADL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\ludandan\\Desktop\\CCS3\\model.py:88\u001b[0m, in \u001b[0;36mTRT.forward\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     85\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state[:,\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,:]\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# TRT\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m TRT_hidden_state \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, hidden_state\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     90\u001b[0m     trt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((hidden_state[:,\u001b[38;5;241m0\u001b[39m:i]\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),hidden_state[:,i],hidden_state[:,i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument tensors in method wrapper_cat)"
     ]
    }
   ],
   "source": [
    "epochs = 400\n",
    "lr = 0.1\n",
    "batch_size = 1\n",
    "\n",
    "train(ffd,trt,trainingloader,valloader,epochs,optimizerF,optimizerT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
